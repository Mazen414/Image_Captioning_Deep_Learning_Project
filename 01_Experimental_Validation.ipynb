{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "d8d38cf2",
        "outputId": "62dcac88-0de5-43b4-b8a4-28234aeac994"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "  print(f'User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7e9ab2e-1319-4909-9b20-7bdf5aef1f4b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7e9ab2e-1319-4909-9b20-7bdf5aef1f4b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving captions.txt to captions.txt\n",
            "Saving features.pkl to features.pkl\n",
            "User uploaded file \"captions.txt\" with length 3319294 bytes\n",
            "User uploaded file \"features.pkl\" with length 133064982 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good forÂ thisÂ dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Ti39sI-AxFG3",
        "outputId": "0e5bf98d-157b-44e6-e584-31da10293998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1894502051.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# create generator using ONLY train_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10d474aa",
        "outputId": "e256ff30-10a4-487c-dba4-2833765ca570"
      },
      "source": [
        "import os\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'features.pkl', 'captions.txt', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b652e120",
        "outputId": "f4dad1ea-2e6b-4626-ef83-0a1c4f024b57"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# Load the features\n",
        "with open('features.pkl', 'rb') as f:\n",
        "    features = pickle.load(f)\n",
        "\n",
        "print(f'Loaded {len(features)} image features.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8091 image features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20da948d",
        "outputId": "0c2ad610-7516-422a-cbdb-f628c0906cea"
      },
      "source": [
        "import re\n",
        "\n",
        "# Function to load captions\n",
        "def load_captions(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# Function to create mapping of image to captions\n",
        "def create_mapping(captions):\n",
        "    mapping = dict()\n",
        "    for line in captions.split('\\n'):\n",
        "        if not line: continue\n",
        "        # First item is the image ID, the rest is the caption\n",
        "        image_id, image_caption = line.split(',', 1)\n",
        "        # Remove file extension from image ID\n",
        "        image_id = image_id.split('.')[0]\n",
        "        # Clean caption\n",
        "        image_caption = image_caption.strip()\n",
        "        # Create a list for each image to store all captions\n",
        "        if image_id not in mapping:\n",
        "            mapping[image_id] = list()\n",
        "        mapping[image_id].append(image_caption)\n",
        "    return mapping\n",
        "\n",
        "# Load captions\n",
        "raw_captions = load_captions('captions.txt')\n",
        "mapping = create_mapping(raw_captions)\n",
        "\n",
        "print(f'Loaded {len(mapping)} images with captions.')\n",
        "# print(mapping['1000268201_693b08cb0e'])\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(captions):\n",
        "    for key, descs in captions.items():\n",
        "        for i, desc in enumerate(descs):\n",
        "            # Tokenize\n",
        "            desc = desc.split()\n",
        "            # Convert to lower case, remove punctuation\n",
        "            desc = [word.lower() for word in desc if word.isalpha()]\n",
        "            # Remove hanging 's' and a\n",
        "            desc = [word for word in desc if len(word)>1]\n",
        "            # Remove tokens with numbers in them\n",
        "            desc = [word for word in desc if word.isalpha()]\n",
        "            # Store as string\n",
        "            descs[i] =  'startseq ' + ' '.join(desc) + ' endseq'\n",
        "\n",
        "# Clean captions\n",
        "clean_text(mapping)\n",
        "\n",
        "# Build vocabulary\n",
        "vocabulary = set()\n",
        "for key in mapping.keys():\n",
        "    for d in mapping[key]:\n",
        "        [vocabulary.add(word) for word in d.split()]\n",
        "\n",
        "print(f'Vocabulary Size: {len(vocabulary)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8092 images with captions.\n",
            "Vocabulary Size: 8352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good forÂ thisÂ dataset.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "QGwYPzX95d4N",
        "outputId": "57360216-e554-41dc-9491-a7025f3cf4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_generator' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1894502051.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# create generator using ONLY train_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7287e45e"
      },
      "source": [
        "# Task\n",
        "Prepare the tokenizer, including fitting it on `mapping` and determining `vocab_size` and `max_length`; define the `data_generator` function which takes image IDs, caption mappings, image features, the tokenizer, max caption length, vocabulary size, and batch size; and build the image captioning model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74cacf0f"
      },
      "source": [
        "## Prepare Tokenizer and Vocabulary\n",
        "\n",
        "### Subtask:\n",
        "Initialize a Keras Tokenizer, fit it on the cleaned captions from your `mapping` variable to build the vocabulary, and determine `vocab_size` and `max_length` for caption sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50d7fc0c"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires initializing a Keras Tokenizer, fitting it on the cleaned captions, and calculating vocabulary size and maximum caption length. This code block will perform all these steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f070041c",
        "outputId": "3130e020-eb74-44bb-9a28-91adc986ac89"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"âš™ï¸ Preparing Tokenizer and Vocabulary...\")\n",
        "\n",
        "# Create a list of all cleaned captions from the mapping dictionary\n",
        "all_captions = []\n",
        "for key in mapping:\n",
        "    for caption in mapping[key]:\n",
        "        all_captions.append(caption)\n",
        "\n",
        "# Initialize the Tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<unk>')\n",
        "\n",
        "# Fit the tokenizer on the list of captions\n",
        "tokenizer.fit_on_texts(all_captions)\n",
        "\n",
        "# Determine vocab_size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(f\"   Vocabulary Size: {vocab_size}\")\n",
        "\n",
        "# Calculate max_length\n",
        "max_length = max(len(s.split()) for s in all_captions)\n",
        "print(f\"   Max Sequence Length: {max_length}\")\n",
        "\n",
        "print(\"âœ… Tokenizer and Vocabulary Prepared!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš™ï¸ Preparing Tokenizer and Vocabulary...\n",
            "   Vocabulary Size: 8354\n",
            "   Max Sequence Length: 32\n",
            "âœ… Tokenizer and Vocabulary Prepared!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbeea337"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully prepared the tokenizer and vocabulary. The next step, as indicated by the error in the notebook and the overall task description, is to define the `data_generator` function, which will be used to feed data to the model during training. This function needs to process batches of image features and their corresponding encoded caption sequences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21a8aa2c",
        "outputId": "17f27e9a-f147-49ff-c18c-b3ad19aa92bf"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"Generating data generator function...\")\n",
        "\n",
        "# Data Generator Function\n",
        "def data_generator(image_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n = 0\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for image_id in image_ids:\n",
        "            n += 1\n",
        "            # retrieve all captions for the image\n",
        "            captions = mapping[image_id]\n",
        "            for caption in captions:\n",
        "                # encode the sequence\n",
        "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence\n",
        "                    out_seq = np.zeros(vocab_size)\n",
        "                    out_seq[out_seq] = 1 # THIS LINE WAS CAUSING ERROR, CHANGED TO out_seq[out_seq_value] = 1\n",
        "                    out_seq[out_seq] = 1 # Corrected: out_seq[out_seq_value] = 1\n",
        "                    out_seq[out_seq] = 1\n",
        "\n",
        "                    # Fix: The line `out_seq[out_seq] = 1` is incorrect. `out_seq` here is an integer index, not a sequence itself.\n",
        "                    # It should be `out_seq_vector = np.zeros(vocab_size); out_seq_vector[out_seq] = 1`\n",
        "                    # Re-writing the output sequence encoding to correctly one-hot encode the next word.\n",
        "                    out_seq_vector = np.zeros(vocab_size)\n",
        "                    out_seq_vector[out_seq] = 1\n",
        "\n",
        "                    # store\n",
        "                    X1.append(features[image_id][0])\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq_vector)\n",
        "            # yield the batch data\n",
        "            if n == batch_size:\n",
        "                yield ([np.array(X1), np.array(X2)], np.array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n = 0\n",
        "\n",
        "print(\"âœ… Data generator function defined!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data generator function...\n",
            "âœ… Data generator function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78448524"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully prepared the tokenizer, vocabulary, and defined the `data_generator` function. The next step, as per the overall task, is to build the image captioning model architecture, which includes defining the input layers for image features and caption sequences, connecting them to a decoder, and compiling the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "6936ab3f",
        "outputId": "482ebe16-b73f-4bfa-c1c8-44d5e6ef74cd"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "print(\"ğŸ—ï¸ Building Image Captioning Model...\")\n",
        "\n",
        "# Encoder - Feature Extractor Model (for image features)\n",
        "# This is the input for the image features (e.g., from VGG16)\n",
        "inputs1 = Input(shape=(2048,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "# Decoder - Sequence Processor Model (for text captions)\n",
        "# This is the input for the partial caption sequence\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "# Decoder - Merging the Encoder and Decoder outputs\n",
        "de1 = Add()([fe2, se3])\n",
        "de2 = Dense(256, activation='relu')(de1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(de2)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Summarize the model\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Plot the model architecture (optional)\n",
        "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "print(\"âœ… Model Built and Compiled!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—ï¸ Building Image Captioning Model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m2,138,624\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m524,544\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8354\u001b[0m)      â”‚  \u001b[38;5;34m2,146,978\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,624</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8354</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,146,978</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,401,250\u001b[0m (20.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,401,250</span> (20.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,401,250\u001b[0m (20.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,401,250</span> (20.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Built and Compiled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f89458c3"
      },
      "source": [
        "## Train the model and evaluate its performance\n",
        "\n",
        "### Subtask:\n",
        "Train the image captioning model using the `data_generator` and then evaluate its performance using BLEU scores on the test set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d1e7240"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps successfully prepared the tokenizer, vocabulary, the `data_generator` function, and the model architecture. The next logical step is to execute the training and evaluation of the model, which was previously attempted but failed due to the `data_generator` not being defined yet. Now that all prerequisites are met, I will re-run the existing code block that handles data splitting, model training, and BLEU score evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "201840e0",
        "outputId": "2acb55ea-9454-445c-e83f-323b4abb0959"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "arrays used as indices must be of integer (or boolean) type",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-780375924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2874187202.py\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(image_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;31m# encode output sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mout_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mout_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# THIS LINE WAS CAUSING ERROR, CHANGED TO out_seq[out_seq_value] = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mout_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# Corrected: out_seq[out_seq_value] = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mout_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e82668e"
      },
      "source": [
        "**Reasoning**:\n",
        "The `IndexError` occurred in the `data_generator` function because `out_seq` (which was an integer representing the word index) was incorrectly used as an index for itself when attempting to one-hot encode. I need to modify the `data_generator` function to correctly create a one-hot encoded vector for the output word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "577c73b7",
        "outputId": "865cced1-04cf-4607-8f0e-8a861b98fc37"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"Generating data generator function...\")\n",
        "\n",
        "# Data Generator Function\n",
        "def data_generator(image_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n = 0\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for image_id in image_ids:\n",
        "            n += 1\n",
        "            # retrieve all captions for the image\n",
        "            captions = mapping[image_id]\n",
        "            for caption in captions:\n",
        "                # encode the sequence\n",
        "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_word_index = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence (one-hot encoding)\n",
        "                    out_seq_vector = np.zeros(vocab_size)\n",
        "                    out_seq_vector[out_word_index] = 1\n",
        "\n",
        "                    # store\n",
        "                    X1.append(features[image_id][0])\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq_vector)\n",
        "            # yield the batch data\n",
        "            if n == batch_size:\n",
        "                yield ([np.array(X1), np.array(X2)], np.array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n = 0\n",
        "\n",
        "print(\"âœ… Data generator function defined!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data generator function...\n",
            "âœ… Data generator function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfef9155"
      },
      "source": [
        "**Reasoning**:\n",
        "The `data_generator` function has been corrected and redefined. The next step is to re-run the training and evaluation code block, which includes data splitting, model training, and BLEU score calculation, as stated in the subtask and previous reasoning. This will attempt to train the model with the fixed generator and then evaluate its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "5c798766",
        "outputId": "012c89b9-bcc4-497f-a2ff-155d5918707d"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "`output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-780375924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\u001b[0m in \u001b[0;36m_from_generator\u001b[0;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTypeSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         raise TypeError(f\"`output_signature` must contain objects that are \"\n\u001b[0m\u001b[1;32m    125\u001b[0m                         \u001b[0;34mf\"subclass of `tf.TypeSpec` but found {type(spec)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         f\"which is not.\")\n",
            "\u001b[0;31mTypeError\u001b[0m: `output_signature` must contain objects that are subclass of `tf.TypeSpec` but found <class 'list'> which is not."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "520937cc"
      },
      "source": [
        "**Reasoning**:\n",
        "The `TypeError` about `output_signature` found `<class 'list'>` suggests that the `data_generator` is yielding a list of NumPy arrays for the model's inputs, where TensorFlow's `model.fit` expects a tuple of NumPy arrays for multi-input models. I need to modify the `data_generator` function to ensure it yields a tuple of input arrays, not a list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d502a22d",
        "outputId": "b838c820-3584-4155-c83a-4a0aca37a37d"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\"Generating data generator function...\")\n",
        "\n",
        "# Data Generator Function\n",
        "def data_generator(image_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n = 0\n",
        "    # loop for ever over images\n",
        "    while 1:\n",
        "        for image_id in image_ids:\n",
        "            n += 1\n",
        "            # retrieve all captions for the image\n",
        "            captions = mapping[image_id]\n",
        "            for caption in captions:\n",
        "                # encode the sequence\n",
        "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "                # split one sequence into multiple X, y pairs\n",
        "                for i in range(1, len(seq)):\n",
        "                    # split into input and output pair\n",
        "                    in_seq, out_word_index = seq[:i], seq[i]\n",
        "                    # pad input sequence\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    # encode output sequence (one-hot encoding)\n",
        "                    out_seq_vector = np.zeros(vocab_size)\n",
        "                    out_seq_vector[out_word_index] = 1\n",
        "\n",
        "                    # store\n",
        "                    X1.append(features[image_id][0])\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq_vector)\n",
        "            # yield the batch data\n",
        "            if n == batch_size:\n",
        "                # Changed from ([np.array(X1), np.array(X2)], np.array(y)) to ((np.array(X1), np.array(X2)), np.array(y))\n",
        "                yield ((np.array(X1), np.array(X2)), np.array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n = 0\n",
        "\n",
        "print(\"âœ… Data generator function defined!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data generator function...\n",
            "âœ… Data generator function defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5df9d72d"
      },
      "source": [
        "**Reasoning**:\n",
        "The `data_generator` function has been corrected and redefined to yield inputs as a tuple. The next step is to re-run the training and evaluation code block, which includes data splitting, model training, and BLEU score calculation, as stated in the subtask and previous reasoning. This will attempt to train the model with the fixed generator and then evaluate its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "814923f6",
        "outputId": "16968d80-1392-4e29-b23c-4c46dc675765"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 2048), found shape=(None, 4096)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3729969972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mspec_dim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                             \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m\"incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 2048), found shape=(None, 4096)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94831f08"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ValueError` indicates a mismatch between the expected input shape of the model's image features (2048) and the actual shape provided by the `data_generator` (4096). I need to modify the model architecture to match the 4096-dimensional image features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "1aaa715c",
        "outputId": "9690b3fe-2c74-415c-fe58-15f6d764c638"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "print(\"ğŸ—ï¸ Building Image Captioning Model...\")\n",
        "\n",
        "# Encoder - Feature Extractor Model (for image features)\n",
        "# This is the input for the image features (e.g., from VGG16)\n",
        "inputs1 = Input(shape=(4096,)) # Corrected input shape from 2048 to 4096\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "# Decoder - Sequence Processor Model (for text captions)\n",
        "# This is the input for the partial caption sequence\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "# Decoder - Merging the Encoder and Decoder outputs\n",
        "de1 = Add()([fe2, se3])\n",
        "de2 = Dense(256, activation='relu')(de1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(de2)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Summarize the model\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Plot the model architecture (optional)\n",
        "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "print(\"âœ… Model Built and Compiled!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—ï¸ Building Image Captioning Model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_2       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m2,138,624\u001b[0m â”‚ input_layer_3[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_3[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m1,048,832\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8354\u001b[0m)      â”‚  \u001b[38;5;34m2,146,978\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_3       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_2       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,624</span> â”‚ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8354</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,146,978</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Built and Compiled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259263aa"
      },
      "source": [
        "**Reasoning**:\n",
        "The model architecture has been rebuilt with the corrected input shape for image features. Now, I need to re-run the training and evaluation code block, which includes data splitting, model training with the corrected `data_generator`, and BLEU score calculation, as stated in the subtask and previous reasonings. This will attempt to train the model and evaluate its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8cded6e5",
        "outputId": "45d4aec2-27c2-4568-8283-22956554a760"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_1_1/lstm_1_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-780375924.py\", line 42, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 583, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 550, in inner_loop\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_1_1/lstm_1_1/Assert/Assert}}]] [Op:__inference_multi_step_on_iterator_2743]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-780375924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_1_1/lstm_1_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-780375924.py\", line 42, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 583, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 550, in inner_loop\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_1_1/lstm_1_1/Assert/Assert}}]] [Op:__inference_multi_step_on_iterator_2743]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d7111ea"
      },
      "source": [
        "**Reasoning**:\n",
        "The `InvalidArgumentError` indicates that the cuDNN-optimized LSTM layer is incompatible with the masking generated by the left-padded sequences from `pad_sequences`. To resolve this, I will disable cuDNN in the LSTM layer by setting `recurrent_activation='sigmoid'` (which implicitly disables cuDNN) to allow the model to train with the current padding strategy, as suggested by the error message's general advice on RNN mask incompatibility with cuDNN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "7217483a",
        "outputId": "f8c586d3-ec30-4321-c2f7-abf0b5267aa1"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "print(\"ğŸ—ï¸ Building Image Captioning Model...\")\n",
        "\n",
        "# Encoder - Feature Extractor Model (for image features)\n",
        "# This is the input for the image features (e.g., from VGG16)\n",
        "inputs1 = Input(shape=(4096,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "# Decoder - Sequence Processor Model (for text captions)\n",
        "# This is the input for the partial caption sequence\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256, recurrent_activation='sigmoid')(se2) # Added recurrent_activation to disable cuDNN implicitly\n",
        "\n",
        "# Decoder - Merging the Encoder and Decoder outputs\n",
        "de1 = Add()([fe2, se3])\n",
        "de2 = Dense(256, activation='relu')(de1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(de2)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Summarize the model\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Plot the model architecture (optional)\n",
        "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "print(\"âœ… Model Built and Compiled!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—ï¸ Building Image Captioning Model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_5       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_4       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_2         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m2,138,624\u001b[0m â”‚ input_layer_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_4[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_2         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_5[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m1,048,832\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8354\u001b[0m)      â”‚  \u001b[38;5;34m2,146,978\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_5       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_4       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_2         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,624</span> â”‚ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_2         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8354</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,146,978</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Built and Compiled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "353f30d9"
      },
      "source": [
        "**Reasoning**:\n",
        "The model architecture has been rebuilt with the LSTM layer configured to implicitly disable cuDNN. Now, I need to re-run the training and evaluation code block, which includes data splitting, model training with the corrected `data_generator` and `model` architecture, and BLEU score calculation, as stated in the subtask and previous reasonings. This will attempt to train the model and evaluate its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3c4cc90e",
        "outputId": "7543d7b3-3bbf-4c26-a916-bf4091e15c40"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node functional_2_1/lstm_2_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-780375924.py\", line 42, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 583, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 550, in inner_loop\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_2_1/lstm_2_1/Assert/Assert}}]] [Op:__inference_multi_step_on_iterator_5274]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-780375924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_2_1/lstm_2_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"/tmp/ipython-input-780375924.py\", line 42, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/function.py\", line 177, in _run_through_graph\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/models/functional.py\", line 648, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\", line 936, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\", line 58, in __call__\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 583, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py\", line 406, in call\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/lstm.py\", line 550, in inner_loop\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_2_1/lstm_2_1/Assert/Assert}}]] [Op:__inference_multi_step_on_iterator_5274]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35fe1fb9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to disable cuDNN in the LSTM layer by setting `recurrent_activation='sigmoid'` was not sufficient, leading to another `InvalidArgumentError`. I need to explicitly set `use_cudnn=False` in the LSTM layer to fully disable cuDNN, as suggested by the error message, and then re-run the training and evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "f04ea777",
        "outputId": "63d62241-45ad-4b8c-9470-3f84e02b65fd"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "print(\"ğŸ—ï¸ Building Image Captioning Model...\")\n",
        "\n",
        "# Encoder - Feature Extractor Model (for image features)\n",
        "# This is the input for the image features (e.g., from VGG16)\n",
        "inputs1 = Input(shape=(4096,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "# Decoder - Sequence Processor Model (for text captions)\n",
        "# This is the input for the partial caption sequence\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256, recurrent_activation='sigmoid', use_cudnn=False)(se2) # Added use_cudnn=False explicitly\n",
        "\n",
        "# Decoder - Merging the Encoder and Decoder outputs\n",
        "de1 = Add()([fe2, se3])\n",
        "de2 = Dense(256, activation='relu')(de1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(de2)\n",
        "\n",
        "# Create the complete model\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Summarize the model\n",
        "print(\n",
        "\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# Plot the model architecture (optional)\n",
        "# plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "print(\"âœ… Model Built and Compiled!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—ï¸ Building Image Captioning Model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_7       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_6       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_3         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m2,138,624\u001b[0m â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_6[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_3         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_7[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m1,048,832\u001b[0m â”‚ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_3 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8354\u001b[0m)      â”‚  \u001b[38;5;34m2,146,978\u001b[0m â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_7       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer_6       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding_3         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,624</span> â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal_3         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> â”‚ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8354</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,146,978</span> â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Built and Compiled!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97872f59"
      },
      "source": [
        "**Reasoning**:\n",
        "The model architecture has been rebuilt with the LSTM layer explicitly configured to disable cuDNN. Now, I need to re-run the training and evaluation code block, which includes data splitting, model training with the corrected `data_generator` and `model` architecture, and BLEU score calculation, as stated in the subtask and previous reasonings. This will attempt to train the model and evaluate its performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e307105",
        "outputId": "dfa9c311-6656-4a52-ce24-33c976a63c45"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8092\n",
            "   Training Set: 7092 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n",
            "\u001b[1m 44/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4:36\u001b[0m 4s/step - loss: 6.7415"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  KeyError: 'image'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/generator_data_adapter.py\", line 52, in get_tf_iterator\n    for batch in self.generator():\n                 ^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-103407383.py\", line 30, in data_generator\n    X1.append(features[image_id][0])\n              ~~~~~~~~^^^^^^^^^^\n\nKeyError: 'image'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_6]]\n  (1) UNKNOWN:  KeyError: 'image'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/generator_data_adapter.py\", line 52, in get_tf_iterator\n    for batch in self.generator():\n                 ^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-103407383.py\", line 30, in data_generator\n    X1.append(features[image_id][0])\n              ~~~~~~~~^^^^^^^^^^\n\nKeyError: 'image'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_8771]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3729969972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) UNKNOWN:  KeyError: 'image'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/generator_data_adapter.py\", line 52, in get_tf_iterator\n    for batch in self.generator():\n                 ^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-103407383.py\", line 30, in data_generator\n    X1.append(features[image_id][0])\n              ~~~~~~~~^^^^^^^^^^\n\nKeyError: 'image'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_6]]\n  (1) UNKNOWN:  KeyError: 'image'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/generator_data_adapter.py\", line 52, in get_tf_iterator\n    for batch in self.generator():\n                 ^^^^^^^^^^^^^^^^\n\n  File \"/tmp/ipython-input-103407383.py\", line 30, in data_generator\n    X1.append(features[image_id][0])\n              ~~~~~~~~^^^^^^^^^^\n\nKeyError: 'image'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_8771]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f7d95b1"
      },
      "source": [
        "**Reasoning**:\n",
        "The `KeyError: 'image'` indicates that the `data_generator` is trying to access `features['image']`, but 'image' is a header from the captions file and not a valid image ID in the `features` dictionary. I need to filter out this invalid key from the `all_image_ids` list before splitting the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4401e3cf",
        "outputId": "f9ccd56e-f2ff-481b-9a0f-ad60701ecf69"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "# Filter out the 'image' key, which is a header from the captions file\n",
        "all_image_ids = [img_id for img_id in all_image_ids if img_id != 'image']\n",
        "\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8091\n",
            "   Training Set: 7091 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 5.1815"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 4s/step - loss: 5.1791\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 4.1312"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 3s/step - loss: 4.1300\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 3.6686"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - loss: 3.6681\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 3.4080"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - loss: 3.4077\n",
            "Epoch 5/20\n",
            "\u001b[1m107/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m4s\u001b[0m 2s/step - loss: 3.2176"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a762a4eb"
      },
      "source": [
        "**Reasoning**:\n",
        "The `KeyError: 'image'` indicates that the `data_generator` is trying to access `features['image']`, but 'image' is a header from the captions file and not a valid image ID in the `features` dictionary. I need to filter out this invalid key from the `all_image_ids` list before splitting the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "169f2af9",
        "outputId": "4b60e560-5cc0-4208-b283-3aa7edad4a68"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences # This import was missing in the original block but needed for evaluation\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"ğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "# Filter out the 'image' key, which is a header from the captions file\n",
        "all_image_ids = [img_id for img_id in all_image_ids if img_id != 'image']\n",
        "\n",
        "random.seed(42) # specific seed so the split is always the same\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "# Reserve 1000 images for Testing, use the rest for Training\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "# create generator using ONLY train_ids\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "# Save the best model\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "# Fit\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    # 1. Get the image feature\n",
        "    feature = features[key][0]\n",
        "\n",
        "    # 2. Generate caption (Predict)\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([feature, sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    # Clean up prediction\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "\n",
        "    # 3. Get actual captions (Ground Truth)\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "# 4. Calculate Score\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\xa0this\\xa0dataset.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Organizing Dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mapping' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-249747203.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Get all image IDs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mall_image_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Filter out the 'image' key, which is a header from the captions file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mall_image_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_image_ids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mapping' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f03f5263"
      },
      "source": [
        "**Reasoning**:\n",
        "The `NameError: name 'mapping' is not defined` indicates that crucial variables and functions like `mapping`, `features`, `tokenizer`, `data_generator`, and `model` are not available in the kernel's current state. To resolve this and ensure the training and evaluation block is self-contained and robust, I need to prepend all necessary code definitions (for loading features, processing captions, preparing the tokenizer, defining the data generator, and building the model) to this block. This will redefine all prerequisites, allowing the execution to proceed correctly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4e9d42ba",
        "outputId": "c4f1d674-af05-4748-8679-ef075b80898d"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
        "from google.colab import files # Import files module\n",
        "\n",
        "# --- File Upload ---\n",
        "print(\"\\nâœ… Please upload your `captions.txt` and `features.pkl` files when prompted.\")\n",
        "print(\"It is expected to prompt an interactive upload widget.\")\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  print(f'   User uploaded file \"{filename}\" with length {len(uploaded[filename])} bytes')\n",
        "print(\"âœ… Files Uploaded (if prompted)!\")\n",
        "\n",
        "# --- Essential Data Loading and Preprocessing ---\n",
        "\n",
        "# From b652e120\n",
        "print(\"\\nâš™ï¸ Loading Image Features...\")\n",
        "with open('features.pkl', 'rb') as f:\n",
        "    features = pickle.load(f)\n",
        "print(f'   Loaded {len(features)} image features.')\n",
        "\n",
        "# From 20da948d\n",
        "print(\"\\nâš™ï¸ Loading and Cleaning Captions...\")\n",
        "def load_captions(filename):\n",
        "    file = open(filename, 'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "def create_mapping(captions):\n",
        "    mapping = dict()\n",
        "    for line in captions.split('\\n'):\n",
        "        if not line: continue\n",
        "        image_id, image_caption = line.split(',', 1)\n",
        "        image_id = image_id.split('.')[0]\n",
        "        image_caption = image_caption.strip()\n",
        "        if image_id not in mapping:\n",
        "            mapping[image_id] = list()\n",
        "        mapping[image_id].append(image_caption)\n",
        "    return mapping\n",
        "\n",
        "raw_captions = load_captions('captions.txt')\n",
        "mapping = create_mapping(raw_captions)\n",
        "print(f'   Loaded {len(mapping)} images with captions (including header, if any).')\n",
        "\n",
        "def clean_text(captions):\n",
        "    for key, descs in captions.items():\n",
        "        for i, desc in enumerate(descs):\n",
        "            desc = desc.split()\n",
        "            desc = [word.lower() for word in desc if word.isalpha()]\n",
        "            desc = [word for word in desc if len(word)>1]\n",
        "            desc = [word for word in desc if word.isalpha()]\n",
        "            descs[i] =  'startseq ' + ' '.join(desc) + ' endseq'\n",
        "\n",
        "clean_text(mapping)\n",
        "vocabulary = set()\n",
        "for key in mapping.keys():\n",
        "    for d in mapping[key]:\n",
        "        [vocabulary.add(word) for word in d.split()]\n",
        "print(f'   Vocabulary Size: {len(vocabulary)} (after cleaning).')\n",
        "print(\"âœ… Captions Loaded and Cleaned!\")\n",
        "\n",
        "# From f070041c\n",
        "print(\"\\nâš™ï¸ Preparing Tokenizer and Vocabulary...\")\n",
        "all_captions_list = [] # Renamed to avoid confusion with image IDs list\n",
        "for key in mapping:\n",
        "    for caption in mapping[key]:\n",
        "        all_captions_list.append(caption)\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='<unk>')\n",
        "tokenizer.fit_on_texts(all_captions_list)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = max(len(s.split()) for s in all_captions_list)\n",
        "print(f\"   Vocabulary Size (from tokenizer): {vocab_size}\")\n",
        "print(f\"   Max Sequence Length: {max_length}\")\n",
        "print(\"âœ… Tokenizer and Vocabulary Prepared!\")\n",
        "\n",
        "# --- Data Generator Function Definition ---\n",
        "\n",
        "# From d502a22d (corrected data_generator)\n",
        "print(\"\\nâš™ï¸ Defining data generator function...\")\n",
        "def data_generator(image_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n = 0\n",
        "    while 1:\n",
        "        for image_id in image_ids:\n",
        "            n += 1\n",
        "            captions = mapping[image_id]\n",
        "            for caption in captions:\n",
        "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
        "                for i in range(1, len(seq)):\n",
        "                    in_seq, out_word_index = seq[:i], seq[i]\n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    out_seq_vector = np.zeros(vocab_size)\n",
        "                    out_seq_vector[out_word_index] = 1\n",
        "                    X1.append(features[image_id][0])\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq_vector)\n",
        "            if n == batch_size:\n",
        "                yield ((np.array(X1), np.array(X2)), np.array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n = 0\n",
        "print(\"âœ… Data generator function defined!\")\n",
        "\n",
        "# --- Model Architecture Definition ---\n",
        "\n",
        "# From f04ea777 (corrected model architecture)\n",
        "print(\"\\nğŸ—ï¸ Building Image Captioning Model...\")\n",
        "inputs1 = Input(shape=(4096,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256, recurrent_activation='sigmoid', use_cudnn=False)(se2)\n",
        "de1 = Add()([fe2, se3])\n",
        "de2 = Dense(256, activation='relu')(de1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(de2)\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n",
        "print(\"âœ… Model Built and Compiled!\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. SPLIT DATA (Train vs Test)\n",
        "# ==========================================\n",
        "print(\"\\nğŸ“Š Organizing Dataset...\")\n",
        "\n",
        "# Get all image IDs\n",
        "all_image_ids = list(mapping.keys())\n",
        "# Filter out the 'image' key, which is a header from the captions file\n",
        "all_image_ids = [img_id for img_id in all_image_ids if img_id != 'image']\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(all_image_ids)\n",
        "\n",
        "test_count = 1000\n",
        "train_ids = all_image_ids[:-test_count]\n",
        "test_ids = all_image_ids[-test_count:]\n",
        "\n",
        "print(f\"   Total Images: {len(all_image_ids)}\")\n",
        "print(f\"   Training Set: {len(train_ids)} images (Used to learn)\")\n",
        "print(f\"   Testing Set:  {len(test_ids)} images (Hidden for exam)\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. TRAIN THE MODEL\n",
        "# ==========================================\n",
        "print(\"\\nğŸš€ STARTING TRAINING (on Training Set only)...\")\n",
        "\n",
        "epochs = 20\n",
        "batch_size = 64\n",
        "steps = len(train_ids) // batch_size\n",
        "\n",
        "train_generator = data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size)\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.h5', monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    steps_per_epoch=steps,\n",
        "    callbacks=[checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ğŸ‰ Training Finished & Saved!\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. SCIENTIFIC EVALUATION (BLEU SCORE)\n",
        "# ==========================================\n",
        "print(f\"\\nğŸ§ª STARTING EVALUATION on {len(test_ids)} hidden images...\")\n",
        "print(\"(This takes about 2-3 minutes)...\")\n",
        "\n",
        "actual, predicted = list(), list()\n",
        "\n",
        "for key in test_ids:\n",
        "    feature = features[key][0]\n",
        "    in_text = 'startseq'\n",
        "    for i in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        # Reshape feature to add a batch dimension for model.predict\n",
        "        yhat = model.predict([np.expand_dims(feature, axis=0), sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = tokenizer.index_word.get(yhat)\n",
        "        if word is None: break\n",
        "        in_text += ' ' + word\n",
        "        if word == 'endseq': break\n",
        "\n",
        "    pred_caption = in_text.replace('startseq', '').replace('endseq', '').split()\n",
        "    references = [d.split() for d in mapping[key]]\n",
        "\n",
        "    actual.append(references)\n",
        "    predicted.append(pred_caption)\n",
        "\n",
        "b1 = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "b2 = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "\n",
        "print('\\n------------------------------------------------')\n",
        "print(f'âœ… FINAL RESULTS:')\n",
        "print(f'   BLEU-1 Score: {b1:.4f} (Accuracy of single words)')\n",
        "print(f'   BLEU-2 Score: {b2:.4f} (Accuracy of pairs of words)')\n",
        "print('------------------------------------------------')\n",
        "print(\"NOTE: A score between 0.4 and 0.6 is considered very good for\\x0athis\\x0adataset.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Please upload your `captions.txt` and `features.pkl` files when prompted.\n",
            "It is expected to prompt an interactive upload widget.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2769b57d-7e26-4c32-84a8-0a6653256757\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2769b57d-7e26-4c32-84a8-0a6653256757\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving captions.txt to captions.txt\n",
            "Saving features.pkl to features.pkl\n",
            "   User uploaded file \"captions.txt\" with length 3319294 bytes\n",
            "   User uploaded file \"features.pkl\" with length 133064982 bytes\n",
            "âœ… Files Uploaded (if prompted)!\n",
            "\n",
            "âš™ï¸ Loading Image Features...\n",
            "   Loaded 8091 image features.\n",
            "\n",
            "âš™ï¸ Loading and Cleaning Captions...\n",
            "   Loaded 8092 images with captions (including header, if any).\n",
            "   Vocabulary Size: 8352 (after cleaning).\n",
            "âœ… Captions Loaded and Cleaned!\n",
            "\n",
            "âš™ï¸ Preparing Tokenizer and Vocabulary...\n",
            "   Vocabulary Size (from tokenizer): 8354\n",
            "   Max Sequence Length: 32\n",
            "âœ… Tokenizer and Vocabulary Prepared!\n",
            "\n",
            "âš™ï¸ Defining data generator function...\n",
            "âœ… Data generator function defined!\n",
            "\n",
            "ğŸ—ï¸ Building Image Captioning Model...\n",
            "\n",
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚  \u001b[38;5;34m2,138,624\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mNotEqual\u001b[0m)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚  \u001b[38;5;34m1,048,832\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m525,312\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚     \u001b[38;5;34m65,792\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8354\u001b[0m)      â”‚  \u001b[38;5;34m2,146,978\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,624</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ not_equal           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,832</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8354</span>)      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,146,978</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,925,538\u001b[0m (22.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,925,538</span> (22.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model Built and Compiled!\n",
            "\n",
            "ğŸ“Š Organizing Dataset...\n",
            "   Total Images: 8091\n",
            "   Training Set: 7091 images (Used to learn)\n",
            "   Testing Set:  1000 images (Hidden for exam)\n",
            "\n",
            "ğŸš€ STARTING TRAINING (on Training Set only)...\n",
            "Epoch 1/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 6.1919 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1126s\u001b[0m 10s/step - loss: 6.1863\n",
            "Epoch 2/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 4.5694 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1121s\u001b[0m 10s/step - loss: 4.5673\n",
            "Epoch 3/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3.8508 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1110s\u001b[0m 10s/step - loss: 3.8501\n",
            "Epoch 4/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3.5178 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1103s\u001b[0m 10s/step - loss: 3.5175\n",
            "Epoch 5/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3.3026 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1104s\u001b[0m 10s/step - loss: 3.3023\n",
            "Epoch 6/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 3.1364 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1105s\u001b[0m 10s/step - loss: 3.1362\n",
            "Epoch 7/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.9993 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1109s\u001b[0m 10s/step - loss: 2.9992\n",
            "Epoch 8/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.9020 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1109s\u001b[0m 10s/step - loss: 2.9018\n",
            "Epoch 9/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.8072 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 10s/step - loss: 2.8072\n",
            "Epoch 10/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.7307 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1108s\u001b[0m 10s/step - loss: 2.7306\n",
            "Epoch 11/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.6665 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1116s\u001b[0m 10s/step - loss: 2.6665\n",
            "Epoch 12/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.6096 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1114s\u001b[0m 10s/step - loss: 2.6096\n",
            "Epoch 13/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.5535 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1119s\u001b[0m 10s/step - loss: 2.5535\n",
            "Epoch 14/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.5070 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1115s\u001b[0m 10s/step - loss: 2.5070\n",
            "Epoch 15/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.4588 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1123s\u001b[0m 10s/step - loss: 2.4588\n",
            "Epoch 16/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.4145 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1121s\u001b[0m 10s/step - loss: 2.4145\n",
            "Epoch 17/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.3828 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1122s\u001b[0m 10s/step - loss: 2.3828\n",
            "Epoch 18/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.3583 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1121s\u001b[0m 10s/step - loss: 2.3582\n",
            "Epoch 19/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.3292 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1122s\u001b[0m 10s/step - loss: 2.3291\n",
            "Epoch 20/20\n",
            "\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - loss: 2.2972 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m110/110\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 10s/step - loss: 2.2971\n",
            "ğŸ‰ Training Finished & Saved!\n",
            "\n",
            "ğŸ§ª STARTING EVALUATION on 1000 hidden images...\n",
            "(This takes about 2-3 minutes)...\n",
            "\n",
            "------------------------------------------------\n",
            "âœ… FINAL RESULTS:\n",
            "   BLEU-1 Score: 0.4325 (Accuracy of single words)\n",
            "   BLEU-2 Score: 0.2578 (Accuracy of pairs of words)\n",
            "------------------------------------------------\n",
            "NOTE: A score between 0.4 and 0.6 is considered very good for\n",
            "this\n",
            "dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ba9bc4e7",
        "outputId": "8048bd01-6724-4e2f-e1b0-5ab1fa3f8d6b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.title('Model Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}